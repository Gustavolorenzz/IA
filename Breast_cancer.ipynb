{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwKbaHTNDn7GgL4fI11yhm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gustavolorenzz/IA/blob/main/Breast_cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnBnpYgNgHTS",
        "outputId": "ff9df98c-cdf8-44b3-844f-688689810683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relatório de Desempenho do Modelo Ótimo:\n",
            "Acurácia: 0.71\n",
            "Matriz de Confusão:\n",
            "[[31 10]\n",
            " [ 7 10]]\n",
            "\n",
            "Resumo de Classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.76      0.78        41\n",
            "           1       0.50      0.59      0.54        17\n",
            "\n",
            "    accuracy                           0.71        58\n",
            "   macro avg       0.66      0.67      0.66        58\n",
            "weighted avg       0.72      0.71      0.71        58\n",
            "\n",
            "Configurações Ótimas:\n",
            "{'classifier__hidden_layer_sizes': (20, 10), 'classifier__learning_rate_init': 0.01, 'classifier__max_iter': 1000, 'classifier__n_iter_no_change': 10, 'classifier__tol': 0.0001, 'classifier__verbose': False}\n",
            "Precisão Média da Validação Cruzada: 0.67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Resultados para Diferentes Topologias e Taxas de Aprendizado:\n",
            "Topologia: (10,), Taxa de Aprendizado: 0.001, Épocas: 1000, Acurácia: 0.67\n",
            "Topologia: (10,), Taxa de Aprendizado: 0.01, Épocas: 480, Acurácia: 0.78\n",
            "Topologia: (10,), Taxa de Aprendizado: 0.1, Épocas: 112, Acurácia: 0.72\n",
            "Topologia: (10,), Taxa de Aprendizado: 0.2, Épocas: 120, Acurácia: 0.67\n",
            "Topologia: (10,), Taxa de Aprendizado: 0.3, Épocas: 80, Acurácia: 0.66\n",
            "Topologia: (10, 10), Taxa de Aprendizado: 0.001, Épocas: 1000, Acurácia: 0.62\n",
            "Topologia: (10, 10), Taxa de Aprendizado: 0.01, Épocas: 219, Acurácia: 0.66\n",
            "Topologia: (10, 10), Taxa de Aprendizado: 0.1, Épocas: 112, Acurácia: 0.57\n",
            "Topologia: (10, 10), Taxa de Aprendizado: 0.2, Épocas: 74, Acurácia: 0.69\n",
            "Topologia: (10, 10), Taxa de Aprendizado: 0.3, Épocas: 20, Acurácia: 0.29\n",
            "Topologia: (20, 10), Taxa de Aprendizado: 0.001, Épocas: 708, Acurácia: 0.71\n",
            "Topologia: (20, 10), Taxa de Aprendizado: 0.01, Épocas: 131, Acurácia: 0.66\n",
            "Topologia: (20, 10), Taxa de Aprendizado: 0.1, Épocas: 113, Acurácia: 0.59\n",
            "Topologia: (20, 10), Taxa de Aprendizado: 0.2, Épocas: 60, Acurácia: 0.55\n",
            "Topologia: (20, 10), Taxa de Aprendizado: 0.3, Épocas: 91, Acurácia: 0.52\n",
            "\n",
            "Resultados para Diferentes Taxas de Aprendizado:\n",
            "Taxa de Aprendizado: 0.001, Épocas: 1000, Acurácia: 0.67\n",
            "Taxa de Aprendizado: 0.01, Épocas: 480, Acurácia: 0.78\n",
            "Taxa de Aprendizado: 0.1, Épocas: 112, Acurácia: 0.72\n",
            "Taxa de Aprendizado: 0.2, Épocas: 120, Acurácia: 0.67\n",
            "Taxa de Aprendizado: 0.3, Épocas: 80, Acurácia: 0.66\n",
            "Taxa de Aprendizado: 0.001, Épocas: 1000, Acurácia: 0.62\n",
            "Taxa de Aprendizado: 0.01, Épocas: 219, Acurácia: 0.66\n",
            "Taxa de Aprendizado: 0.1, Épocas: 112, Acurácia: 0.57\n",
            "Taxa de Aprendizado: 0.2, Épocas: 74, Acurácia: 0.69\n",
            "Taxa de Aprendizado: 0.3, Épocas: 20, Acurácia: 0.29\n",
            "Taxa de Aprendizado: 0.001, Épocas: 708, Acurácia: 0.71\n",
            "Taxa de Aprendizado: 0.01, Épocas: 131, Acurácia: 0.66\n",
            "Taxa de Aprendizado: 0.1, Épocas: 113, Acurácia: 0.59\n",
            "Taxa de Aprendizado: 0.2, Épocas: 60, Acurácia: 0.55\n",
            "Taxa de Aprendizado: 0.3, Épocas: 91, Acurácia: 0.52\n",
            "\n",
            "Resumo Final Usando o Melhor Modelo do Grid Search:\n",
            "Melhor Configuração de Hiperparâmetros: {'classifier__hidden_layer_sizes': (20, 10), 'classifier__learning_rate_init': 0.01, 'classifier__max_iter': 1000, 'classifier__n_iter_no_change': 10, 'classifier__tol': 0.0001, 'classifier__verbose': False}\n",
            "Precisão Média da Validação Cruzada: 0.67\n",
            "Acurácia no Conjunto de Teste: 0.71\n",
            "Matriz de Confusão:\n",
            "[[31 10]\n",
            " [ 7 10]]\n",
            "Relatório de Classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.76      0.78        41\n",
            "           1       0.50      0.59      0.54        17\n",
            "\n",
            "    accuracy                           0.71        58\n",
            "   macro avg       0.66      0.67      0.66        58\n",
            "weighted avg       0.72      0.71      0.71        58\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImPipeline\n",
        "\n",
        "# Lendo dados do arquivo CSV.\n",
        "df = pd.read_csv('/content/breast-cancer.csv')\n",
        "\n",
        "# Ajustando os dados: Transformação de texto em números e ajuste de escala.\n",
        "num_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "cat_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "preprocess = ColumnTransformer([\n",
        "    ('num', num_pipe, ['deg-malig']),\n",
        "    ('cat', cat_pipe, ['age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'breast', 'breast-quad', 'irradiat'])\n",
        "])\n",
        "\n",
        "# Separando as variáveis independentes da dependente.\n",
        "X, y = df.drop('Class', axis=1), df['Class'].map({'no-recurrence-events': 0, 'recurrence-events': 1})\n",
        "\n",
        "# Dividindo o conjunto de dados para treino e teste.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
        "\n",
        "# Aplicando o pré-processamento e balanceando as classes no treino.\n",
        "X_train_prep = preprocess.fit_transform(X_train)\n",
        "X_test_prep = preprocess.transform(X_test)\n",
        "X_train_bal, y_train_bal = SMOTE().fit_resample(X_train_prep, y_train)\n",
        "\n",
        "# Definição da pipeline completa com SMOTE e MLPClassifier.\n",
        "pipeline = ImPipeline([\n",
        "    ('preprocessor', preprocess),\n",
        "    ('smote', SMOTE()),\n",
        "    ('classifier', MLPClassifier(max_iter=1000, verbose=False))\n",
        "])\n",
        "\n",
        "# Parâmetros para o Grid Search com objetivo de otimizar a rede neural.\n",
        "params_grid = {\n",
        "    'classifier__hidden_layer_sizes': [(10,), (10, 10), (20, 10)],\n",
        "    'classifier__learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.3],\n",
        "    'classifier__max_iter': [1000],\n",
        "    'classifier__verbose': [False],\n",
        "    'classifier__n_iter_no_change': [10],\n",
        "    'classifier__tol': [0.0001]\n",
        "}\n",
        "\n",
        "# Implementação do Grid Search com Cross-Validation.\n",
        "grid_search_cv = GridSearchCV(\n",
        "    pipeline, params_grid, cv=5, scoring='accuracy',\n",
        "    verbose=0, n_jobs=1, error_score='raise'\n",
        ")\n",
        "\n",
        "# Execução do Grid Search no conjunto de treino.\n",
        "grid_search_cv.fit(X_train, y_train)\n",
        "\n",
        "# Selecionando o melhor modelo encontrado.\n",
        "optimal_model = grid_search_cv.best_estimator_\n",
        "\n",
        "# Avaliação do modelo ótimo no conjunto de teste.\n",
        "predictions = optimal_model.predict(X_test)\n",
        "\n",
        "# Apresentação dos resultados de desempenho.\n",
        "print(\"Relatório de Desempenho do Modelo Ótimo:\")\n",
        "print(f\"Acurácia: {accuracy_score(y_test, predictions):.2f}\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "print(\"\\nResumo de Classificação:\")\n",
        "print(classification_report(y_test, predictions))\n",
        "\n",
        "# Exibindo os parâmetros ótimos.\n",
        "print(\"Configurações Ótimas:\")\n",
        "print(grid_search_cv.best_params_)\n",
        "print(f\"Precisão Média da Validação Cruzada: {grid_search_cv.best_score_:.2f}\")\n",
        "\n",
        "# Repetindo o processo para diferentes topologias e taxas de aprendizado.\n",
        "topology_results = []\n",
        "learning_rate_results = []\n",
        "\n",
        "for size in [(10,), (10, 10), (20, 10)]:\n",
        "    for lr in [0.001, 0.01, 0.1, 0.2, 0.3]:\n",
        "        model = MLPClassifier(hidden_layer_sizes=size, learning_rate_init=lr, max_iter=1000, verbose=False)\n",
        "        model.fit(X_train_bal, y_train_bal)\n",
        "\n",
        "        # Predições e avaliação para cada configuração\n",
        "        pred = model.predict(X_test_prep)\n",
        "        accuracy = accuracy_score(y_test, pred)\n",
        "        conf_mat = confusion_matrix(y_test, pred)\n",
        "        class_rep = classification_report(y_test, pred, output_dict=True)\n",
        "\n",
        "        # Armazenando os resultados\n",
        "        topology_results.append((size, lr, model.n_iter_, accuracy))\n",
        "        learning_rate_results.append((lr, model.n_iter_, accuracy))\n",
        "\n",
        "# Apresentando os resultados para diferentes topologias e taxas de aprendizado.\n",
        "print(\"\\nResultados para Diferentes Topologias e Taxas de Aprendizado:\")\n",
        "for res in topology_results:\n",
        "    size, lr, epochs, accuracy = res\n",
        "    print(f\"Topologia: {size}, Taxa de Aprendizado: {lr}, Épocas: {epochs}, Acurácia: {accuracy:.2f}\")\n",
        "\n",
        "print(\"\\nResultados para Diferentes Taxas de Aprendizado:\")\n",
        "for res in learning_rate_results:\n",
        "    lr, epochs, accuracy = res\n",
        "    print(f\"Taxa de Aprendizado: {lr}, Épocas: {epochs}, Acurácia: {accuracy:.2f}\")\n",
        "\n",
        "# Resumo final usando o melhor modelo do Grid Search.\n",
        "print(\"\\nResumo Final Usando o Melhor Modelo do Grid Search:\")\n",
        "print(f\"Melhor Configuração de Hiperparâmetros: {grid_search_cv.best_params_}\")\n",
        "print(f\"Precisão Média da Validação Cruzada: {grid_search_cv.best_score_:.2f}\")\n",
        "print(f\"Acurácia no Conjunto de Teste: {accuracy_score(y_test, predictions):.2f}\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "print(\"Relatório de Classificação:\")\n",
        "print(classification_report(y_test, predictions))\n",
        "\n",
        "\n"
      ]
    }
  ]
}